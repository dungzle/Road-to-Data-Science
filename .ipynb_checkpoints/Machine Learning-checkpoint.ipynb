{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ What is Machine Learning?\n",
    "\n",
    "In traditional programming, a computer need to be told exactly what to do (explicit instructions: if you see X, then do Y). We configure a machine to accept our input and produce an output based on the algorithm (input = command, output = predetermined response). When problem get trickier and we can't explicitly instruct the computer what to do, we need machine learning\n",
    "\n",
    "Machine Learning is similar to how human learn: we give the computer the data and tools it needs to study and solve the problem without being told what to do. The computer has ability to adapt, evolve, and learn. \n",
    "\n",
    "**Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ How Machine Learning works?\n",
    "\n",
    "UC Berkeley breaks out the learning system of a machine learning algorithm into three main parts.\n",
    "1. **A Decision Process**: In general, machine learning algorithms are used to make a prediction or classification. Based on some input data, which can be labelled or unlabeled, your algorithm will produce an estimate about a pattern in the data.\n",
    "\n",
    "\n",
    "2. **An Cost/Error Function**: An cost/error function serves to evaluate the prediction of the model. If there are known examples, an error function can make a comparison to assess the accuracy of the model.\n",
    "\n",
    "\n",
    "3. **An Model Optimization Process**: If the model can fit better to the data points in the training set, then weights are adjusted to reduce the discrepancy between the known example and the model estimate. The algorithm will repeat this evaluate and optimize process, updating weights autonomously until a threshold of accuracy has been met.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Different Ways a Machine learns:\n",
    "1. **Supervised Learning** (we teach the computer how to do sth)\n",
    "\n",
    "    Supervised Learning is defined by its use of *labeled datasets* to train algorithms that to classify data or predict outcomes accurately. As input data is fed into the model, it adjusts its weights until the model has been fitted appropriately. This occurs as part of the cross validation process to ensure that the model avoids overfitting or underfitting. Some methods used in supervised learning include neural networks, naïve bayes, linear regression, logistic regression, decision tree/random forest, support vector machine (SVM), and more.\n",
    "\n",
    "\n",
    "2. **Unsupervised Learning** (we let the computer learn by itself)\n",
    "\n",
    "    Unsupervised Learning uses machine learning algorithms to analyze and cluster *unlabeled datasets*. These algorithms discover hidden patterns or data groupings without the need for human intervention. Some algorithms used in unsupervised learning include neural networks, k-means clustering, probabilistic clustering methods, and more.\n",
    "        \n",
    "\n",
    "3. **Semi-supervised learning** offers a happy medium between supervised and unsupervised learning. During training, it uses a smaller labeled data set to guide classification and feature extraction from a larger, unlabeled data set. Semi-supervised learning can solve the problem of having not enough labeled data (or not being able to afford to label enough data) to train a supervised learning algorithm. \n",
    "\n",
    "\n",
    "4. **Reinforcement learning** is a behavioral machine learning model that is similar to supervised learning, but the algorithm isn’t trained using sample data. This model learns as it goes by using trial and error. A sequence of successful outcomes will be reinforced to develop the best recommendation or policy for a given problem.\n",
    "\n",
    "Source: https://www.ibm.com/cloud/learn/machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV/ Supervised Learning\n",
    "\n",
    "There are two types of Supervised Learning:\n",
    "   1. Regression = estimate the mapping function (f) from the input (x) to *numerical or continuous* output (y).\n",
    "   2. Classification = estimate the mapping function (f) from the input (x) to *discrete or categorical* output (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=F6GSRDoB-Cg&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN&index=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by feeding the training data to a Learning Algorithm. Then, that algorithm will output a function called hypothesis $h_{\\theta}(x)$. This hypothesis will map the new data to a predicted value:\n",
    "$$h_{\\theta}(x^{i}) = {\\theta_0} + {\\theta_1}{x_1} + ... + {\\theta_n}{x_n}$$\n",
    "\n",
    "How to choose those parameters $\\theta_i$ so that $h_{\\theta}(x)$ $\\approx$ y for given (x,y)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis:**\n",
    "$$h_{\\theta}(x^{i}) = {\\theta_0} + {\\theta_1}{x_1} + ... + {\\theta_n}{x_n}$$\n",
    "\n",
    "**Parameters**\n",
    "$$\\theta = vector [{\\theta_0}, {\\theta_1}, ... , {\\theta_n}]$$\n",
    "\n",
    "**Cost Function / Error function:**\n",
    "$$ J({\\theta}) = \\frac{1}{2m} \\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i})^2$$\n",
    "\n",
    "**Goal: Minimize $J({\\theta_0},{\\theta_1},..,{\\theta_n})$**\n",
    "\n",
    "*Notation:*\n",
    "- *m = number of training examples*\n",
    "- *($x^{i}, y^{i}$) = $i^{th}$ example*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to find the mininum of the cost function $J({\\theta})$:**\n",
    "1. **Gradient descent** = an optimization algorithm for finding a local minimum of a differentiable function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient.\n",
    "\n",
    "\n",
    "2. **Normal equation** = linear algebra approach using matrix multiplication to find the optimal parameters $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Gradient Descent:**\n",
    "\n",
    "We simultaneously update ${\\theta_j}$ until J(${\\theta_j}$) converge to a local minimum\n",
    "\n",
    "    repeat until convergence (for j = 1, .., n) {\n",
    "$${\\theta_j} := {\\theta_j} - \\alpha\\frac{\\partial}{\\partial {\\theta_j}}J({\\theta})$$\n",
    "\n",
    "    or\n",
    "    \n",
    "$${\\theta_0} := {\\theta_0} - \\alpha\\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i})$$\n",
    "$${\\theta_j} := {\\theta_j} - \\alpha\\frac{1}{m} \\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i}){x_j}^i$$\n",
    "    \n",
    "                                                 for j = 1,2,3,...,n\n",
    "    }\n",
    "where:\n",
    "- $\\alpha$ = learning rate\n",
    "- $\\frac{\\partial}{\\partial {\\theta_j}}J({\\theta})$ = partial derivative of cost function J with respect to $\\theta_j$ = slope of tangent line\n",
    "\n",
    "<img src=\"img/gradient_descent.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "- **Feature Scaling**: make sure features are on a similar scale, which help gradient descent to converge more quickly \n",
    "\n",
    "    We should get every feature into approximately -1 $\\leq x_i \\leq 1$ range. \n",
    "    \n",
    "    We can do that by applying *Mean Normalization*: \n",
    "$$x_i = \\frac{{x_i} - {\\mu}_i}{s_i}$$\n",
    "     where: $s_i$ = range of $x_i$ in training set\n",
    "     \n",
    "     \n",
    "- **Making sure gradient descent is working correctly**: $J(\\theta)$ should decrease after every iteration\n",
    "  \n",
    "   If gradient descent is not working, use smaller $\\alpha$ (learning rate). \n",
    "   \n",
    "   - If $\\alpha$ is too small, gradient descent can be slow to converge.\n",
    "   \n",
    "   - If $\\alpha$ is too large, $J(\\theta)$ may not converge or not decrease on every iteration\n",
    "   \n",
    "<img src=\"img/learning_rate.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Normal Equation:**\n",
    "\n",
    "Hypothesis\n",
    "$$h_{\\theta}(x^{i}) = {\\theta_0} + {\\theta_1}{x_1} + ... + {\\theta_n}{x_n}$$\n",
    "\n",
    "Let define $x_0 = 1$, then we have:\n",
    "$$h_{\\theta}(x^{i}) = {\\theta_0}{x_0} + {\\theta_1}{x_1} + ... + {\\theta_n}{x_n}$$\n",
    "\n",
    "$$ X = [{x_0},{x_1},..,{x_n}]^T$$\n",
    "\n",
    "We can calculate the optimal $\\theta$ by using below Normal Equation:\n",
    "$$\\theta = ({{X^T}X})^{-1}{X^T}y$$\n",
    "\n",
    "*Note: If ${X^T}X$ is non-invertible, try to remove redundant features or use regularization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to use Gradient Descent or Normal Equation?**\n",
    "\n",
    "Only choose Normal Equation if data is small\n",
    "\n",
    "| **Gradient Descent** | **Normal Equation** |\n",
    "| :-: | :-: |\n",
    "| Need to choose $\\alpha$ | Don't need to choose $\\alpha$ |\n",
    "| Need many iterations | Don't need many iterations |\n",
    "| Works well when n is large | Slow if n is large (because compute $({{X^T}X})^{-1}$ is $O(n^3)$|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Regularization:\n",
    "\n",
    "Regularization is a form of regression, which constrains or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting.\n",
    "\n",
    "Regularization can significantly reduce the variance of the model, without substantial increase in its bias.\n",
    "\n",
    "$$ J({\\theta}) = \\frac{1}{2m}\\Big[\\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i})^2 + \\lambda\\sum_{j=1}^{m}{\\theta_j}^2\\Big]$$\n",
    "\n",
    "λ is the regularization parameter controls trade off between two goals\n",
    "\n",
    "1) Want to fit the training set well\n",
    "\n",
    "2) Want to keep parameters small\n",
    "\n",
    "*Note: Pick λ carefully. If λ is too large we penalize ALL the parameters so all the parameters end up being close to 0. If this happens, it's like we got rid of all the terms in the hypothesis. This results in underfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bayesian Algorithm (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.youtube.com/watch?v=O2L2Uv9pdDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Assumptions:**\n",
    "\n",
    "The fundamental Naive Bayes assumption: \"Each feature makes an **independent** and **equal** contribution to the outcome\". In detail:\n",
    "- **Independent** = no pair of features are dependent. For example, the Temperature being hot has nothing to do with the Humidity, or the Outlook being rainy has no effect on the Winds.\n",
    "\n",
    "\n",
    "- **Equal** = each feature is given the same weight (or importance). For example, knowing only temperature and humidity alone can't predict the outcome accuratey. None of the attributes is irrelevant and assumed to be contributing equally to the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Bayes' Theorem:**\n",
    "\n",
    "Bayes' Theorem finds the probability of an event occurring given the probability of another event that has already occurred:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) P(A)}{P(B)}$$\n",
    "\n",
    "where A and B are events and P(B) ≠ 0.\n",
    "\n",
    "Basically, we are trying to find probability of event A, given the event B is true. Event B is also termed as evidence.\n",
    "P(A) is the priori of A (the prior probability = probability of event before evidence is seen). The evidence is an attribute value of an unknown instance(here, it is event B).\n",
    "P(A|B) is a posteriori probability of B, i.e. probability of event after evidence is seen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) k-Nearest Neighbour (k-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # VI/ How to Improve and Evaluate Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debugging a Learning Algorithm:\n",
    "\n",
    "Suppose we have implemented regularized linear regression to predict housing prices.\n",
    "$$ J({\\theta}) = \\frac{1}{2m}\\Big[\\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i})^2 + \\lambda\\sum_{j=1}^{m}{\\theta_j}^2\\Big]$$\n",
    "However, when we test our hypothesis on a new set of houses, we find that it makes unacceptably large errors in its prediction. What should we try next:\n",
    "   - **Fix High Variance (overfit):**\n",
    "       - Get more training examples\n",
    "       - Try smaller set of features\n",
    "   - **Fix High Bias (underfit):**\n",
    "       - Getting additional features, polynomial features: \n",
    "       - Try decreasing or increasing $\\lambda$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model selection\n",
    "\n",
    "Split dataset into training, cross validation, test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diagnosing Bias vs Variance\n",
    "\n",
    "Suppose our learning algorithm is performing less well than we were hoping:\n",
    "- **Bias (underfit)**: \n",
    "    \n",
    "     Both $J_{train}(\\theta)$ and $J_{test}(\\theta)$ are high: $J_{test}(\\theta) \\approx J_{train}(\\theta)$\n",
    "    \n",
    "    \n",
    "- **Variance (overfit)**: \n",
    "    \n",
    "    $J_{train}(\\theta)$ is low, while $J_{test}(\\theta)$ is high: $J_{test}(\\theta) >> J_{train}(\\theta)$\n",
    "\n",
    "<img src=\"img/bias_variance.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Regularization and Bias-Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression with Regularization**\n",
    "\n",
    "$$ J({\\theta}) = \\frac{1}{2m}\\Big[\\sum_{i=1}^{m}(h_{\\theta}(x^{i}) - y^{i})^2 + \\lambda\\sum_{j=1}^{m}{\\theta_j}^2\\Big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much.\n",
    "\n",
    "If a learning algorithm is suffering from high variance, getting more training data is likely to help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Performance of Machine Learning Model\n",
    "\n",
    "### a) Confusion Matrix:\n",
    "   - Type I Error (FP) = $\\alpha$ = rejecting the true null hypothesis\n",
    "   - Type II Error (FN) = $\\beta$ = failing to reject the false null hypothesis\n",
    "          e.g.: You decide to get tested for COVID-19 based on mild symptoms. \n",
    "                Null hypothesis = You don't have COVID:\n",
    "                - Type I error (FP): the test result says you are positive with COVID, but you actually don’t.\n",
    "                - Type II error (FN): the test result says you are negative with COVID, but you actually do.\n",
    "                \n",
    "<img src=\"img/Confusion_matrix_ML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Accuracy:\n",
    "\n",
    "**Accuracy** = the number of correct predictions over the total number of predictions.\n",
    "\n",
    "$$Accuracy = \\frac{TN + TP}{TN + FN + TP + FP}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Precision:\n",
    "\n",
    "**Precision** = Within everything that has been predicted as a positive, how many of them are actual positive.\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Recall:\n",
    "\n",
    "**Recall** = Within everything that actually is positive, how many did the model succeed to find.\n",
    "\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) F1 score:\n",
    "\n",
    "**F1 Score** = the harmonic mean of precision and recall.\n",
    "\n",
    "$$F1score = 2*\\frac{Precision*Recall}{Precision + Recall}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Metrics Comparison:\n",
    "\n",
    "In this section, we want to find out when we should and should not use above metrics. \n",
    "\n",
    "Let's consider below scenario: \n",
    "        \n",
    "        There are 90 people who are healthy (negative) and 10 people who have COVID (positive). \n",
    "        \n",
    "        Now let’s see the confusion matrix and calculate metrics\n",
    "\n",
    "| True Negative = 90 | False Positive = 0 |\n",
    "| :-: | :-: |\n",
    "| **False Negative = 9** | **True Positive = 1** |\n",
    "\n",
    "$$Accuracy = \\frac{90 + 1}{90 + 9 + 0 + 1} = 91\\%$$\n",
    "\n",
    "$$Precision = \\frac{1}{1 + 0} = 100\\%$$\n",
    "\n",
    "$$Recall = \\frac{1}{1 + 9} = 10\\%$$\n",
    "\n",
    "$$F1score = 2*\\frac{1*0.1}{1 + 0.1} = 0.09\\%$$\n",
    "\n",
    "**Accuracy** is very high = 91%. However, in this scenario, accuracy is a very poor metrics because in all of 10 people having COVID, it can only correctly identify 1 of them (10%). It would be very dangerous if we cannot detect those COVID patients.\n",
    "\n",
    "**Precision** = 100%. Precision only measures the positive predictions, so it misses all the Negative predictions. Therefore, it is also not a good metric in this case.\n",
    "\n",
    "In this situation, the cost of False Negative is significant. We should choose **Recall** or **F1 Score** as a performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Summary:\n",
    "\n",
    "**Accuracy** is not a good metric when the data set is unbalanced.\n",
    "\n",
    "**Precision** is a good measure to determine, when the **costs of False Positive is high**. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n",
    "\n",
    "**Recall** is the model metric we use to select our best model when there is a **high cost associated with False Negative**.\n",
    "For instance: in sick patient detection, if a sick patient (Actual Positive) goes through the test and predicted as not sick (Predicted Negative). The cost associated with False Negative will be extremely high if the sickness is contagious.\n",
    "\n",
    "**F1 Score** is a better measure to use if we need to **seek a balance between Precision and Recall** AND there is an **uneven class distribution** (large number of Actual Negatives).\n",
    "\n",
    "In conclusion, when you have the possibility to do so, you should definitely **look at multiple metrics for each of the models** that you try out. Each metric has advantages and disadvantages and each of them will give you specific information on the strengths and weaknesses of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
